(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{116:function(e,t,n){"use strict";n.d(t,"a",(function(){return p})),n.d(t,"b",(function(){return m}));var a=n(0),r=n.n(a);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=r.a.createContext({}),u=function(e){var t=r.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=u(e.components);return r.a.createElement(c.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},b=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=u(n),b=a,m=p["".concat(o,".").concat(b)]||p[b]||h[b]||i;return n?r.a.createElement(m,l(l({ref:t},c),{},{components:n})):r.a.createElement(m,l({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=b;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var c=2;c<i;c++)o[c]=n[c];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"},82:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return o})),n.d(t,"toc",(function(){return l})),n.d(t,"default",(function(){return c}));var a=n(3),r=(n(0),n(116));const i={title:"Machine Learning"},o={unversionedId:"generative/machine-learning",id:"generative/machine-learning",isDocsHomePage:!1,title:"Machine Learning",description:'"001100 010010 011110 100001"',source:"@site/book/generative/machine-learning.md",slug:"/generative/machine-learning",permalink:"/book/generative/machine-learning",version:"current",sidebar:"main",previous:{title:"Evolution",permalink:"/book/generative/evolution"},next:{title:"Sonification",permalink:"/book/generative/sonification"}},l=[{value:"Theory",id:"theory",children:[{value:"How ML &quot;learns&quot;",id:"how-ml-learns",children:[]},{value:"Musical example",id:"musical-example",children:[]},{value:"Definitions",id:"definitions",children:[]}]},{value:"Magenta",id:"magenta",children:[{value:"MusicRNN",id:"musicrnn",children:[]}]}],s={toc:l};function c({components:e,...t}){return Object(r.b)("wrapper",Object(a.a)({},s,t,{components:e,mdxType:"MDXLayout"}),Object(r.b)("blockquote",null,Object(r.b)("p",{parentName:"blockquote"},'"001100 010010 011110 100001"'),Object(r.b)("p",{parentName:"blockquote"},Object(r.b)("a",{parentName:"p",href:"https://futurama.fandom.com/wiki/Time_Code"},"Bender, Futurama"))),Object(r.b)("p",null,"TODO"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Neural networks"),Object(r.b)("li",{parentName:"ul"},"Recurrent neural networks (RNN)"),Object(r.b)("li",{parentName:"ul"},"Convolutional neural networks (CNN)"),Object(r.b)("li",{parentName:"ul"},"Generative adversarial networks (GAN)"),Object(r.b)("li",{parentName:"ul"},"Variational Auto Encoders (VAE)"),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",{parentName:"li",href:"https://magenta.tensorflow.org/"},"https://magenta.tensorflow.org/")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",{parentName:"li",href:"https://paperswithcode.com/"},"https://paperswithcode.com/")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",{parentName:"li",href:"https://arxiv.org/archive/cs"},"https://arxiv.org/archive/cs")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",{parentName:"li",href:"https://www.kaggle.com/"},"https://www.kaggle.com/")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=HKRJuz6o2uY"},"https://www.youtube.com/watch?v=HKRJuz6o2uY"))),Object(r.b)("p",null,"In this chapter we're going to look at how to use Machine Learning (ML) to\ngenerate music. So far, we've defined our own rules for what we want to make.\nWith ML, we'll see how we can instead teach a system to learn and extrapolate\nit's own rules, by learning from existing data."),Object(r.b)("h2",{id:"theory"},"Theory"),Object(r.b)("p",null,"ML is a huge topic, but at its core is a simple objective: to teach a program to\nmodel a set of data. This model can then be used to understand (or generate) new\ndata that the program has never seen before."),Object(r.b)("p",null,"We won't delve too deep here, as we'll see we can go a long way without much\ntheory, but it's useful to have a rough idea of how ML works in order to\nevaluate different models and what they're capable of."),Object(r.b)("p",null,"It's worth noting that we're using the term ML loosely to cover neural networks,\ndeep learning, and more specifically for the purposes of this chapter,\ngenerative deep learning."),Object(r.b)("h3",{id:"how-ml-learns"},'How ML "learns"'),Object(r.b)("p",null,"The gist of the learning process is as follows:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},'We first define a model, which is a series of "layers" of "neurons" that\nperform calculations on the data as it passes through them. The type and\nnumber of layers and neurons depend on the type of the data and the task we\'re\ntrying to accomplish. The layers and their arrangement, without any learned\nweights (see next point) is also called a "network".')),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},'We initialize the model with a set of random "weights" (random floating point\nnumbers) for each layer in the network. These weights define how data passes\nbetween the layers/neurons and are where the actual "learning" is stored.')),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"We train the model by showing it data that includes the correct answer for the\ntask. If we're training a model to identify photos of cats, our training data\nwould consist of lots of photos labeled 'cat' or 'not cat'.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"We repeat this process for all of the examples in our training data, and for\nmultiple iterations (\"epochs\"). As it goes, the model is constantly adjusting\nthe weights between neurons to try and get it's final output to match the\ncorrect answer. In this way, the model learns which pattern of neurons signify\na correct answer. If the data passing through triggers those neurons, it must\nbe a cat! In other words, it's finding the optimal set of weights that model\nimage data that is 'cat' and 'not cat'."))),Object(r.b)("p",null,"This is a very (very) simplified view of what's happening in a neural network,\nand there are many variations on this process. It's also rather abstract, so a\nmusical example may help."),Object(r.b)("h3",{id:"musical-example"},"Musical example"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Suppose we train a model by showing it MIDI files of all of Bach's works. The\nnetwork might learn that given an A, the next note is often a G#, with a\ncorresponding C note in the bass. The more it sees that pattern, the more\ncertain it becomes (i.e. that neural path becomes stronger). As it sees other\nexamples, it may begin to learn more generally that the next note is often two\nsteps up from the first, and the bass note is 5 steps down.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Now, when we give our model a note, and ask it to predict a next note and a\nbass note, it might predict the pattern it has learned. The likelihood of it\npredicting this pattern corresponds to how certain it is, which is a product\nof how many times it has seen the pattern in comparison with others.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"In this way, we can see how the model's learning is highly dependent on the\ntype and amount of data it was trained on. A model trained on Bach would be\nuseless at generating 12-bar blues. Similarly a model trained on a few\nexamples would only be able to reproduce patterns found in those examples."))),Object(r.b)("h3",{id:"definitions"},"Definitions"),Object(r.b)("p",null,"As with any scientific discipline, ML comes with an array of acronyms and lingo\nthat can be overwhelming to the uninitiated. Just a handful of these terms are\nenough to navigate this chapter:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Network")," \u2013 The specific arrangement of layers used to create the model.\nThese often have 3-letter acronyms that define the type and purpose of the\nnetwork e.g. RNN (Recurrent Neural Network), CNN (Convolutional Neural\nNetwork), (GAN) Generative Adversarial Network, VAE (Variational Auto\nEncoder), etc.")),Object(r.b)("p",null,"Gist: Optimize a loss function = find optimal set of weights to model the data"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Init with random weights"),Object(r.b)("li",{parentName:"ul"},"Model takes in data as input (training data with labels, supervised vs.\nunsupervised?)"),Object(r.b)("li",{parentName:"ul"},"At each pass over the data, it compares it's output to the actual data (i.e.\nerror)"),Object(r.b)("li",{parentName:"ul"},"It nudges all the weights and tries again"),Object(r.b)("li",{parentName:"ul"},"If the error rate decreases, it knows it's going in the right direction"),Object(r.b)("li",{parentName:"ul"},"In this way, the network learns to model the data (training the model, the\nlearning in machine learning)"),Object(r.b)("li",{parentName:"ul"},"Now we have a trained model, it can infer a result given new data it has never\nseen")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Different models for different tasks"),Object(r.b)("li",{parentName:"ul"},"ML, Deep Learning, AI"),Object(r.b)("li",{parentName:"ul"},"Model vs network (names, versions)"),Object(r.b)("li",{parentName:"ul"},"Training"),Object(r.b)("li",{parentName:"ul"},"Prediction/inference"),Object(r.b)("li",{parentName:"ul"},"Pre-built models"),Object(r.b)("li",{parentName:"ul"},"Pre-trained models, checkpoints")),Object(r.b)("h2",{id:"magenta"},"Magenta"),Object(r.b)("h3",{id:"musicrnn"},"MusicRNN"),Object(r.b)("pre",null,Object(r.b)("code",{parentName:"pre",className:"language-js"},"music_rnn = new mm.MusicRNN(\n  'https://storage.googleapis.com/magentadata/js/checkpoints/music_rnn/basic_rnn'\n)\nmusic_rnn.initialize()\n\nconst { createEnv, fx, inst, seq, music } = tuplet\nconst { c4, d4, e4, f4, g4, c5, rest } = music.pitches\nconst { wn, qn, den, sn, hn, ent } = music.durations\n\nconst notes = [\n  [c4, qn],\n  [c4, qn],\n  [c4, den],\n  [d4, sn],\n  [e4, qn],\n]\n\nconsole.log(notes)\n")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"MusicVAE")))}c.isMDXComponent=!0}}]);
<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>JavaScript · Gen.js</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="&lt;p&gt;This article is a general introduction to the Web Audio API aimed at web&lt;/p&gt;
"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="JavaScript · Gen.js"/><meta property="og:type" content="website"/><meta property="og:url" content="https://meleyal.github.io/gen/"/><meta property="og:description" content="&lt;p&gt;This article is a general introduction to the Web Audio API aimed at web&lt;/p&gt;
"/><meta name="twitter:card" content="summary"/><link rel="shortcut icon" href="/gen/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css"/><script type="text/javascript" src="/gen/js/custom.js"></script><script type="text/javascript" src="https://unpkg.com/@meleyal/gen/gen.js"></script><link rel="stylesheet" href="/gen/css/prism.css"/><link rel="stylesheet" href="/gen/css/main.css"/><script src="/gen/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/gen/"><h2 class="headerTitle">Gen.js</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/gen/docs/introduction" target="_self">Docs</a></li><li class=""><a href="https://github.com/meleyal/gen" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Primers</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Welcome</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/introduction">Introduction</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Primers</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/primers/generative">Generative</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/primers/music">Music</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/gen/docs/primers/javascript">JavaScript</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Music</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/music/notes">Notes</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/music/scales">Scales</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/music/timing">Timing</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/music/structure">Structure</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Generative</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/generative/repetition">Repetition</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/randomness">Randomness</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/probability">Probability</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/grammars">Grammars</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/recursion">Recursion</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/evolution">Evolution</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/machine-learning">Machine Learning</a></li><li class="navListItem"><a class="navItem" href="/gen/docs/generative/sonification">Sonification</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Course</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/course/outline">Course Outline</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">API</h3><ul class=""><li class="navListItem"><a class="navItem" href="/gen/docs/api/">API Reference</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              const headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                if (event.target.tagName === 'A') {
                  document.body.classList.remove('tocActive');
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">JavaScript</h1></header><article><div><span><p>This article is a general introduction to the Web Audio API aimed at web
developers who are interested in extending their skills to work with audio and
music applications.</p>
<p>We start by defining what the Web Audio API is and where it came from, then move
on to cover two of its key concepts that may be unfamiliar to web developers:
graphs and timing. Along the way we'll get a feel for the API and what it can
do.</p>
<h2><a class="anchor" aria-hidden="true" id="background"></a><a href="#background" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Background</h2>
<p>The Web Audio API is a set of APIs for generating and processing audio in the
browser. It's designed by the
<a href="https://www.w3.org/2011/audio/">W3C Audio Working Group</a>, steered by Google,
Mozilla, and the BBC, and chartered to &quot;add advanced sound and music synthesis
capabilities to the Open Web Platform.&quot;</p>
<p>It has been in development
<a href="https://www.w3.org/TR/2011/WD-webaudio-20111215/">since 2011</a>, with the spec
recently reaching v1.0 (with
<a href="https://github.com/WebAudio/web-audio-api-v2">v2.0 in the works</a>) and becoming
a <a href="https://www.w3.org/TR/webaudio/">W3C Candidate Recomendation</a>. Despite its
candiditate status, it's already well supported in browsers,
<a href="https://caniuse.com/#feat=audio-api">reaching 94% of users</a> at time of writing.</p>
<p>Common use-cases cited for the Web Audio API are to bring music composition and
audio editing tools (e.g. Ableton Live, Logic Pro) to the browser, as well as
enabling real-time audio for games and VR. Beyond these obvious applications,
bringing sound to the mix opens up another dimension for building a richer, more
sensory web.</p>
<h2><a class="anchor" aria-hidden="true" id="the-web-audio-api"></a><a href="#the-web-audio-api" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Web Audio API</h2>
<p>The Web Audio API itself is relatively small, and is covered comprehensively by
the
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">MDN Web Docs</a>,
the go-to source for understanding everything the API can do.</p>
<p>Rather than repeat the documentation here, we'll instead focus on the two
aspects of working with the API that are most different from traditional web
development, namely the audio graph and the timing model. We'll cover just
enough of the API to get up and running creating our own bleeps and bloops.</p>
<h2><a class="anchor" aria-hidden="true" id="graphs-nodes"></a><a href="#graphs-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graphs &amp; Nodes</h2>
<p>As web developers, we're used to working with the DOM, a tree data structure
representing a hierarchy of nodes that we traverse via parent, sibling and child
relationships. The Web Audio API, on the other hand (and audio apps in general),
organizes nodes in a <em>graph</em> data structure.</p>
<p>[ILLUSTRATION]</p>
<p><em>Source</em> nodes generate signals and are the inputs of our system. These signals
are routed through <em>effect</em> nodes to modify them in various ways. Everything
ends up at a single <em>destination</em> node, i.e. your speakers, producing the
audible output of our system. This is digital signal processing 101.</p>
<p>It's worth taking a moment to understand the fundamental differences between
tree and graph data structures.
<a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">Graph theory</a> is
it's own rich topic, but a key point to note is that a graph is not a heirarchy,
but is instead like a flow chart or electrical circuit. Each node is 'equal' and
can be connected to any (and many) other nodes, and connections can be circular
(in fact this is essential to produce certain types of effects).</p>
<p>If we think about it, this is not such a new concept. We build pages (nodes)
which we link together to form websites and apps (graphs), which together form
the internet, itself a graph of servers, routers, etc.</p>
<p>You might come across graphs described in more technical terms. Graph nodes are
also know as <em>vertices</em>, with the connections between them known as <em>edges</em>.
Traversing a graph is done by following its edges. A graph data structure
generally has ways to find which vertices are connected (either directly or via
other vertices), and insert and remove vertices and edges at given points in the
graph. Specifically, the Web Audio API uses a <em>directed graph</em>, that is, the
signals flow in a defined direction.</p>
<p>A big part of working with the Web Audio API involves creating nodes and making
sure they are wired up correctly in our graph. So let's see how this works...</p>
<h3><a class="anchor" aria-hidden="true" id="creating-our-graph"></a><a href="#creating-our-graph" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating Our Graph</h3>
<p>Our graph exists in an <code>AudioContext</code>. Everything we do via the Web Audio API
happens in this context, similar to how a <code>&lt;canvas&gt;</code> element creates its own
environment for drawing. We'll generally only create a single <code>AudioContext</code> per
app and use its factory methods to create the nodes of our graph:</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">let</span> osc <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createOscillator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">let</span> vol <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createGain</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
osc<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>vol<span class="token punctuation">)</span>
vol<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span>destination<span class="token punctuation">)</span>
</code></pre>
<p>Here we create an <code>AudioContext</code>, and from it create two different node types.
an <code>OscillatorNode</code>, a type of <em>source</em> node, and a <code>GainNode</code>, a type of
<em>effect</em> node (we'll cover what these nodes actually do shortly). We connect the
<code>OscillatorNode</code> to the <code>GainNode</code>, and the <code>GainNode</code> to the <em>destination</em> node
of the <code>AudioContext</code> i.e. our speakers. Our graph looks as follows (rendered in
Chrome with the <a href="https://google.github.io/audion/">Web Audio Inspector</a>).</p>
<p><img src="/gen/docs/assets/primers/javascript/basic-graph.png" alt=""></p>
<h2><a class="anchor" aria-hidden="true" id="nodes"></a><a href="#nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Nodes</h2>
<p>Everything we create in our graph is a node. All nodes implement the
<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode"><code>AudioNode</code></a>
interface, with additional properties and methods specific to their type.</p>
<p>A node's properties can be get and set as you'd expect, but with an additional
super-power: they implement the
<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a>
interface, meaning changes to them can be scheduled over time:</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">let</span> osc <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createOscillator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">// Set frequency now</span>
osc<span class="token punctuation">.</span>frequency <span class="token operator">=</span> <span class="token number">440</span>

<span class="token comment">// Change frequency in 1 second</span>
oscillator<span class="token punctuation">.</span>frequency<span class="token punctuation">.</span><span class="token function">setValueAtTime</span><span class="token punctuation">(</span><span class="token number">880</span><span class="token punctuation">,</span> context<span class="token punctuation">.</span>currentTime <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>Nodes all implement the <code>connect()</code> method, which is how you connect the output
of one node to the input of others. This chaining is what creates our graph.</p>
<p>Nodes themselves can be grouped into two types: Source Nodes and Effect Nodes.</p>
<h3><a class="anchor" aria-hidden="true" id="source-nodes"></a><a href="#source-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Source Nodes</h3>
<p>Source nodes are anything that produce an audio signal and are the inputs of our
system. There are several types of source node, but we'll cover just the two
most common here:</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode"><code>OscillatorNode</code></a>
– for synthesizing our own sounds.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a>
– for playing back recorded sounds (samples).</li>
</ul>
<p>All source nodes have a <code>start()</code> and <code>stop()</code> method, which as you might guess,
start and stop them producing their audio signal.</p>
<p><strong>Note:</strong> Source nodes are single use only, or 'fire and forget'. Once a node
has stopped (either by manually calling <code>stop()</code>, or by reaching the end of the
sample it was playing), it cannot be restarted. In creating a piano instrument,
our instinct might be to create 88 nodes, one for each key. Instead, we actually
need to create a new node each time a key is pressed. In this way, our audio
graph is not something fixed that we define ahead of time, but is instead a
dynamic structure that changes as new nodes are created and discarded. Source
nodes are intentionally cheap to create and stopped nodes are automatically
garbage-collected for us.</p>
<h4><a class="anchor" aria-hidden="true" id="oscillatornode"></a><a href="#oscillatornode" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>OscillatorNode</h4>
<p>To synthesize our own sounds, we'd use an <code>OscillatorNode</code>. This produces a
waveform (sine, square, triangle, etc.) oscillating at a given frequency
(specified in hertz). By combining different types of oscillators and effects,
we can produce an infinite range of sounds.</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">const</span> bass <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createOscillator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
bass<span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token string">'sine'</span>
bass<span class="token punctuation">.</span>frequency <span class="token operator">=</span> <span class="token number">220</span>
bass<span class="token punctuation">.</span>frequency<span class="token punctuation">.</span><span class="token function">linearRampToValueAtTime</span><span class="token punctuation">(</span><span class="token number">880</span><span class="token punctuation">,</span> context<span class="token punctuation">.</span>currentTime <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">const</span> hi <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createOscillator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
hi<span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token string">'square'</span>
hi<span class="token punctuation">.</span>frequency <span class="token operator">=</span> <span class="token number">660</span>
hi<span class="token punctuation">.</span>frequency<span class="token punctuation">.</span><span class="token function">linearRampToValueAtTime</span><span class="token punctuation">(</span><span class="token number">880</span><span class="token punctuation">,</span> context<span class="token punctuation">.</span>currentTime <span class="token operator">+</span> <span class="token number">6</span><span class="token punctuation">)</span>

bass<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span>destination<span class="token punctuation">)</span>
hi<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span>destination<span class="token punctuation">)</span>

bass<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
hi<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="audiobuffersourcenode"></a><a href="#audiobuffersourcenode" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>AudioBufferSourceNode</h4>
<p>To play back recorded sounds (samples), we'd use an <code>AudioBufferSourceNode</code>.
This node is responsible for playing back and controlling the sample, but the
sample itself is stored in an <code>AudioBuffer</code>. In this way we can load a sample
once, and use it many times.</p>
<p>Loading a sample is a two step process. We first need to fetch it over the
network, then decode it into a format that <code>AudioBuffer</code> understands.</p>
<p>The whole process of loading, decoding, and finally playing back a sample looks
as follows:</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">fetch</span><span class="token punctuation">(</span><span class="token string">'http://example.com/meow.mp3'</span><span class="token punctuation">)</span>
<span class="token keyword">const</span> arrayBuffer <span class="token operator">=</span> <span class="token keyword">await</span> response<span class="token punctuation">.</span><span class="token function">arrayBuffer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">const</span> audioBuffer <span class="token operator">=</span> <span class="token keyword">await</span> context<span class="token punctuation">.</span><span class="token function">decodeAudioData</span><span class="token punctuation">(</span>arrayBuffer<span class="token punctuation">)</span>

<span class="token keyword">const</span> sourceNode <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createBufferSource</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
sourceNode<span class="token punctuation">.</span>buffer <span class="token operator">=</span> audioBuffer
sourceNode<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span>destination<span class="token punctuation">)</span>
sourceNode<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="effect-nodes"></a><a href="#effect-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Effect Nodes</h3>
<p>We can route an audio signal (coming from a source node) through a wide range of
effect nodes. These modify the incoming signal in some way, producing a new
signal as output. The Web Audio API defines some basic primitives, which can be
combined to create all sorts of effects. The most common ones are:</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/GainNode"><code>GainNode</code></a> –
adjusts the volume of a signal. By applying this over time we can also model
ADSR envelopes (e.g. if a sound starts abruptly or fades in slowly).</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/BiquadFilterNode"><code>BiquadFilterNode</code></a> -
cut or boost certain frequencies of a signal</li>
<li>ConvolverNode - apply reverb to a signal so it sounds like it's in a certain
physical space e.g. a small room or large hall.</li>
<li>DelayNode - apply a delay the the outgoing signal, used for all sorts of
effects from echoes to phasing.</li>
<li>DynamicsCompressorNode – applies compression to a signal to control its
dynamic range (e.g. to avoid distortion)</li>
<li>WaveShaperNode – applies distortion to the signal.</li>
<li>PannerNode – places the audio in the stereo field (i.e. to the left or right
in stereo output).</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="destination-node"></a><a href="#destination-node" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Destination Node</h3>
<p>The detination node is the final node in the chain and represents our audio
output device (i.e. our sound card). This is provided for us as the
<code>destination</code> node of our AudioContext. In addition, there's also an
offlineAudioContext with its own destination if we want to render our audio to
disk, for example.</p>
<h2><a class="anchor" aria-hidden="true" id="timing-model"></a><a href="#timing-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Timing Model</h2>
<p>To understand the timing model, we need to understand under the hood, control
thread = your code, rendering thread = where audio is actually computed.</p>
<p>Timing: has it's own internal clock. Separate from JS clock. JS clock can be
thought of as lazy/relative/imprecise. Usually we'd schedule a callback in
2000ms. JS will schedule this and run when it's done with other tasks, in
roughly 2 seconds.</p>
<p>Web Audio clock is absolute time. Precise. Seconds, not milliseconds! Relative
to the current time.</p>
<p>ILLUSTRATION?</p>
<p>Current time is defined by the AudioContext. It starts counting up from the
moment the AudioContext is created. We can't change it, we can only get it and
schedule things relative to it:</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
context<span class="token punctuation">.</span>currentTime <span class="token comment">// => 0.1234</span>
</code></pre>
<p>As you can see, the Web Audio API doesn't give us much to work with here. We
need to invent our own timing abstraction to work with beats, bars, time
signatures etc. But that's for a future article!</p>
<h2><a class="anchor" aria-hidden="true" id="aside-autoplay-policy"></a><a href="#aside-autoplay-policy" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Aside: Autoplay Policy</h2>
<p>Needs interaction. Needs some hijinx.</p>
<ul>
<li>Chrome: <code>chrome://flags/#autoplay-policy</code> – no longer working as of v76</li>
<li>Firefox: enabled by default?</li>
<li>Safari: ?</li>
<li>Edge: ?</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="conclusion"></a><a href="#conclusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>The WAA is a well defined and adopted/supported technology that's actively
developed. It is and will continue to enable a whole range of previously
native-tethered apps to move to the web.</p>
<p>The WAA provides only the basic primitives. Because it's use-cases are wide.
Depending on what we want to do, we have to build our own abstractions. There
are already a range of libraries for music, game audio, VR?, machine learning.</p>
<p>If we understand two basic concepts: graph/nodes and timing model, we have a
good foundation for working at a higher level and make cool stuff.</p>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 10/25/2019</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/gen/docs/primers/music"><span class="arrow-prev">← </span><span>Music</span></a><a class="docs-next button" href="/gen/docs/music/notes"><span>Notes</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#background">Background</a></li><li><a href="#the-web-audio-api">The Web Audio API</a></li><li><a href="#graphs-nodes">Graphs &amp; Nodes</a><ul class="toc-headings"><li><a href="#creating-our-graph">Creating Our Graph</a></li></ul></li><li><a href="#nodes">Nodes</a><ul class="toc-headings"><li><a href="#source-nodes">Source Nodes</a></li><li><a href="#effect-nodes">Effect Nodes</a></li><li><a href="#destination-node">Destination Node</a></li></ul></li><li><a href="#timing-model">Timing Model</a></li><li><a href="#aside-autoplay-policy">Aside: Autoplay Policy</a></li><li><a href="#conclusion">Conclusion</a></li></ul></nav></div></div></body></html>